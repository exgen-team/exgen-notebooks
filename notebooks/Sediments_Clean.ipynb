{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5daea71b-6668-4d64-a67e-86c43d35a0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warn] UTF-8 decode failed — retrying with 'latin1' encoding.\n",
      "[Info] Loaded NWQLD_Geochem_Seds.csv → (84977, 108)\n",
      "[Note] Missing numeric columns (skipped): ['Au2', 'Au3', 'Au4', 'F']\n",
      "[Saved] C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NWQLD\\NWQLD_Geochem_Seds_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# JUPYTER NOTEBOOK CELL — Clean NWQLD_Geochem_Seds.csv to NWQLD_Geochem_Seds_cleaned.csv\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Paths\n",
    "# =========================\n",
    "INPUT_CSV  = r\"C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NWQLD\\NWQLD_Geochem_Seds.csv\"\n",
    "OUTPUT_CSV = r\"C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NWQLD\\NWQLD_Geochem_Seds_cleaned.csv\"\n",
    "\n",
    "# Optional delimiter / encoding hints\n",
    "CSV_SEP = None        # e.g., \";\" if semicolon-delimited; None lets pandas guess\n",
    "UTF8_FIRST = True     # try UTF-8 first, then latin1 if it fails\n",
    "\n",
    "# Columns to convert to numbers + apply negative rules\n",
    "NUMERIC_COLUMNS = [\n",
    "    \"Au\",\"Au1\",\"Au2\",\"Au3\",\"Au4\",\"Cu\",\"Pb\",\"Zn\",\"Ag\",\"As\",\"Bi\",\"Mo\",\"Mn\",\"Fe\",\"Ni\",\"Co\",\"Cr\",\n",
    "    \"V\",\"Ba\",\"Cd\",\"Sn\",\"Sb\",\"Hg\",\"Te\",\"P\",\"W\",\"Zr\",\"Ti\",\"Mg\",\"Th\",\"U\",\"Pt\",\"Pd\",\"S\",\"F\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def normalize_number_string(s: str) -> str:\n",
    "    \"\"\"Normalize number-like text (preserves decimals) to help parsing.\"\"\"\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = s.strip()\n",
    "    s = s.replace(\"%\", \"\").replace(\"−\", \"-\")  # drop literal %; normalize unicode minus\n",
    "    if \",\" in s and \".\" not in s:              # comma as decimal\n",
    "        s = s.replace(\",\", \".\")\n",
    "    s = re.sub(r\"[^0-9.\\-]+\", \"\", s)           # keep digits, dot, minus\n",
    "    if s.count(\".\") > 1:                       # collapse multiple dots\n",
    "        first = s.find(\".\")\n",
    "        s = s[: first + 1] + s[first + 1:].replace(\".\", \"\")\n",
    "    return s\n",
    "\n",
    "def to_numeric(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce a Series to numeric using normalization first.\"\"\"\n",
    "    return pd.to_numeric(series.map(normalize_number_string), errors=\"coerce\")\n",
    "\n",
    "def apply_negative_rules_to_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Apply your rules:\n",
    "      - values < -99  → NaN\n",
    "      - other negatives → abs(value) / 2 (becomes positive and halved)\n",
    "    \"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    s = s.mask(s < -99, np.nan)\n",
    "    s = s.mask((s < 0) & (s >= -99), abs(s) / 2)\n",
    "    return s\n",
    "\n",
    "def make_new_hole_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    New_Hole_ID = Prospect_Code + '_' + Company + '_' + Sheet_Number + '_' + (Hole_ID or Sheet_Number)\n",
    "    \"\"\"\n",
    "    for col in [\"Prospect_Code\", \"Company\", \"Sheet_Number\"]:\n",
    "        if col not in df.columns:\n",
    "            print(f\"[Warn] Missing column '{col}', using blanks.\")\n",
    "            df[col] = \"\"\n",
    "        df[col] = df[col].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "    tail = df[\"Hole_ID\"].fillna(\"\").astype(str).str.strip() if \"Hole_ID\" in df.columns else df[\"Sheet_Number\"]\n",
    "    df[\"New_Hole_ID\"] = (\n",
    "        df[\"Prospect_Code\"] + \"_\" + df[\"Company\"] + \"_\" + df[\"Sheet_Number\"] + \"_\" + tail\n",
    "    ).str.replace(r\"\\s+\", \"_\", regex=True).str.replace(r\"_+\", \"_\", regex=True).str.strip(\"_\")\n",
    "    return df\n",
    "\n",
    "def read_csv_fallback(path: str, sep=None, utf8_first=True) -> pd.DataFrame:\n",
    "    \"\"\"Read CSV with UTF-8 first, then latin1 fallback.\"\"\"\n",
    "    kwargs = {\"dtype\": str, \"low_memory\": False}\n",
    "    if sep is not None:\n",
    "        kwargs[\"sep\"] = sep\n",
    "    if utf8_first:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=\"utf-8\", **kwargs)\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"[Warn] UTF-8 decode failed — retrying with 'latin1' encoding.\")\n",
    "            return pd.read_csv(path, encoding=\"latin1\", **kwargs)\n",
    "    else:\n",
    "        return pd.read_csv(path, encoding=\"latin1\", **kwargs)\n",
    "\n",
    "# =========================\n",
    "# Load → Clean → Save\n",
    "# =========================\n",
    "if not os.path.exists(os.path.dirname(OUTPUT_CSV)):\n",
    "    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "\n",
    "df = read_csv_fallback(INPUT_CSV, sep=CSV_SEP, utf8_first=UTF8_FIRST)\n",
    "print(f\"[Info] Loaded {os.path.basename(INPUT_CSV)} → {df.shape}\")\n",
    "\n",
    "# Build New_Hole_ID first (before numeric coercion)\n",
    "df = make_new_hole_id(df)\n",
    "\n",
    "# Convert only the specified numeric columns and apply negative rules\n",
    "missing_cols = [c for c in NUMERIC_COLUMNS if c not in df.columns]\n",
    "for col in NUMERIC_COLUMNS:\n",
    "    if col in df.columns:\n",
    "        df[col] = to_numeric(df[col])\n",
    "        df[col] = apply_negative_rules_to_series(df[col])\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"[Note] Missing numeric columns (skipped): {missing_cols}\")\n",
    "\n",
    "# Save cleaned CSV\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"[Saved] {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f05495-4147-44f3-bf1d-a6cf9b2fa2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py311] *",
   "language": "python",
   "name": "conda-env-py311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
