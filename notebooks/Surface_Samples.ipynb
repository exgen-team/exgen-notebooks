{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a717544-72e3-40e0-93d2-b8c08d67b88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Loaded NW-East_QLD_Geochem_rocks.xlsx → (71732, 119)\n",
      "[Note] Missing numeric columns in NW-East_QLD_Geochem_rocks.xlsx (skipped): ['Au2', 'Au3', 'Au4', 'F']\n",
      "[Saved] C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NW-East_Isa\\All_QLD_Geochem_rocks_cleaned.csv\n",
      "[Info] Loaded NW-East_QLD_Geochem_Soils.xlsx → (337085, 104)\n",
      "[Note] Missing numeric columns in NW-East_QLD_Geochem_Soils.xlsx (skipped): ['Au2', 'Au3', 'Au4', 'F']\n",
      "[Saved] C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NW-East_Isa\\All_QLD_Geochem_Soils_cleaned.csv\n",
      "[Info] Loaded NW-East_QLD_Geochem_Seds.xlsx → (131128, 108)\n",
      "[Note] Missing numeric columns in NW-East_QLD_Geochem_Seds.xlsx (skipped): ['Au2', 'Au3', 'Au4', 'F']\n",
      "[Saved] C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NW-East_Isa\\All_QLD_Geochem_Seds_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# JUPYTER NOTEBOOK CELL — Clean Rocks/Soils/Seds with lock-tolerant Excel reader\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Paths / Settings\n",
    "# =========================\n",
    "BASE_FOLDER = r\"C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\"\n",
    "ROCKS_XLSX = os.path.join(BASE_FOLDER, \"NW-East_QLD_Geochem_rocks.xlsx\")\n",
    "SOILS_XLSX = os.path.join(BASE_FOLDER, \"NW-East_QLD_Geochem_Soils.xlsx\")\n",
    "SEDS_XLSX  = os.path.join(BASE_FOLDER, \"NW-East_QLD_Geochem_Seds.xlsx\")\n",
    "\n",
    "OUTDIR = r\"C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NW-East_Isa\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# If your data aren't on the first sheet, set the sheet names/indices here:\n",
    "ROCKS_SHEET = 0\n",
    "SOILS_SHEET = 0\n",
    "SEDS_SHEET  = 0\n",
    "\n",
    "# Columns to convert to numbers + apply negative rules\n",
    "NUMERIC_COLUMNS = [\n",
    "    \"Au\",\"Au1\",\"Au2\",\"Au3\",\"Au4\",\"Cu\",\"Pb\",\"Zn\",\"Ag\",\"As\",\"Bi\",\"Mo\",\"Mn\",\"Fe\",\"Ni\",\"Co\",\"Cr\",\n",
    "    \"V\",\"Ba\",\"Cd\",\"Sn\",\"Sb\",\"Hg\",\"Te\",\"P\",\"W\",\"Zr\",\"Ti\",\"Mg\",\"Th\",\"U\",\"Pt\",\"Pd\",\"S\",\"F\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def normalize_number_string(s: str) -> str:\n",
    "    \"\"\"Normalize number-like text (preserves decimals) to help parsing.\"\"\"\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = s.strip()\n",
    "    s = s.replace(\"%\", \"\").replace(\"−\", \"-\")  # remove literal %; normalize unicode minus\n",
    "    # If comma but no dot, treat comma as decimal separator\n",
    "    if \",\" in s and \".\" not in s:\n",
    "        s = s.replace(\",\", \".\")\n",
    "    # Keep digits, a single dot, and a minus\n",
    "    s = re.sub(r\"[^0-9.\\-]+\", \"\", s)\n",
    "    # If multiple dots, keep first as decimal point\n",
    "    if s.count(\".\") > 1:\n",
    "        first = s.find(\".\")\n",
    "        s = s[: first + 1] + s[first + 1:].replace(\".\", \"\")\n",
    "    return s\n",
    "\n",
    "def to_numeric(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce a Series to numeric using normalization first.\"\"\"\n",
    "    return pd.to_numeric(series.map(normalize_number_string), errors=\"coerce\")\n",
    "\n",
    "def apply_negative_rules_to_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Apply your rules:\n",
    "      - values < -99  → NaN\n",
    "      - other negatives → abs(value) / 2 (becomes positive and halved)\n",
    "    \"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    s = s.mask(s < -99, np.nan)\n",
    "    s = s.mask((s < 0) & (s >= -99), abs(s) / 2)\n",
    "    return s\n",
    "\n",
    "def make_new_hole_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    New_Hole_ID = Prospect_Code + '_' + Company + '_' + Sheet_Number + '_' + (Hole_ID or Sheet_Number)\n",
    "    \"\"\"\n",
    "    for col in [\"Prospect_Code\", \"Company\", \"Sheet_Number\"]:\n",
    "        if col not in df.columns:\n",
    "            print(f\"[Warn] Missing column '{col}', using blanks.\")\n",
    "            df[col] = \"\"\n",
    "        df[col] = df[col].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "    tail = df[\"Hole_ID\"].fillna(\"\").astype(str).str.strip() if \"Hole_ID\" in df.columns else df[\"Sheet_Number\"]\n",
    "    df[\"New_Hole_ID\"] = (\n",
    "        df[\"Prospect_Code\"] + \"_\" + df[\"Company\"] + \"_\" + df[\"Sheet_Number\"] + \"_\" + tail\n",
    "    ).str.replace(r\"\\s+\", \"_\", regex=True).str.replace(r\"_+\", \"_\", regex=True).str.strip(\"_\")\n",
    "    return df\n",
    "\n",
    "def read_excel_safely(path: str, sheet, attempts: int = 5, delay_s: float = 2.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust Excel loader:\n",
    "      1) Try pandas.read_excel(engine='openpyxl')\n",
    "      2) On PermissionError, retry a few times\n",
    "      3) Fallback: openpyxl read-only mode -> build DataFrame\n",
    "    \"\"\"\n",
    "    # 1 & 2: pandas with retries\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            return pd.read_excel(path, sheet_name=sheet, dtype=str, engine=\"openpyxl\")\n",
    "        except PermissionError as e:\n",
    "            if i < attempts - 1:\n",
    "                print(f\"[Warn] Permission denied opening {os.path.basename(path)}. \"\n",
    "                      f\"Close Excel/OneDrive sync on the file if open. Retrying in {delay_s:.0f}s...\")\n",
    "                time.sleep(delay_s)\n",
    "            else:\n",
    "                print(\"[Warn] Falling back to openpyxl read-only mode...\")\n",
    "        except Exception as e:\n",
    "            # Other errors -> break to fallback\n",
    "            print(f\"[Warn] read_excel failed ({type(e).__name__}: {e}). Falling back...\")\n",
    "            break\n",
    "\n",
    "    # 3) Fallback: openpyxl read-only\n",
    "    try:\n",
    "        import openpyxl\n",
    "        wb = openpyxl.load_workbook(path, read_only=True, data_only=True)\n",
    "        ws = wb[wb.sheetnames[sheet]] if isinstance(sheet, int) else wb[sheet]\n",
    "        rows_iter = ws.values\n",
    "        headers = next(rows_iter)\n",
    "        df = pd.DataFrame(rows_iter, columns=[str(h).strip() if h is not None else f\"Unnamed_{i}\"\n",
    "                                              for i, h in enumerate(headers)])\n",
    "        wb.close()\n",
    "        # Ensure string dtype to match our downstream expectations\n",
    "        for c in df.columns:\n",
    "            df[c] = df[c].astype(str).where(df[c].notna(), None)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise PermissionError(\n",
    "            f\"Unable to read '{path}'. It may be locked by Excel/OneDrive, or inaccessible.\\n\"\n",
    "            f\"Details: {type(e).__name__}: {e}\"\n",
    "        )\n",
    "\n",
    "def clean_file(input_xlsx: str, sheet, output_csv: str):\n",
    "    \"\"\"Load, build New_Hole_ID, clean numeric columns, save CSV.\"\"\"\n",
    "    if not os.path.exists(input_xlsx):\n",
    "        print(f\"[Error] File not found: {input_xlsx}\")\n",
    "        return\n",
    "\n",
    "    df = read_excel_safely(input_xlsx, sheet)\n",
    "    print(f\"[Info] Loaded {os.path.basename(input_xlsx)} → {df.shape}\")\n",
    "\n",
    "    # Build New_Hole_ID first\n",
    "    df = make_new_hole_id(df)\n",
    "\n",
    "    # Convert only specified numeric columns and apply negative rules\n",
    "    missing_cols = [c for c in NUMERIC_COLUMNS if c not in df.columns]\n",
    "    for col in NUMERIC_COLUMNS:\n",
    "        if col in df.columns:\n",
    "            df[col] = to_numeric(df[col])\n",
    "            df[col] = apply_negative_rules_to_series(df[col])\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"[Note] Missing numeric columns in {os.path.basename(input_xlsx)} (skipped): {missing_cols}\")\n",
    "\n",
    "    # Save CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"[Saved] {output_csv}\")\n",
    "\n",
    "# =========================\n",
    "# Run for Rocks / Soils / Sediments\n",
    "# =========================\n",
    "clean_file(ROCKS_XLSX, ROCKS_SHEET, os.path.join(OUTDIR, \"All_QLD_Geochem_rocks_cleaned.csv\"))\n",
    "clean_file(SOILS_XLSX, SOILS_SHEET, os.path.join(OUTDIR, \"All_QLD_Geochem_Soils_cleaned.csv\"))\n",
    "clean_file(SEDS_XLSX,  SEDS_SHEET,  os.path.join(OUTDIR, \"All_QLD_Geochem_Seds_cleaned.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd967642-5918-406b-a430-0d3da9ee8ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py311] *",
   "language": "python",
   "name": "conda-env-py311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
