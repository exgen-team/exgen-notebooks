{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4314a192-c770-42e5-8b27-ed2ec38f7780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Loaded NWQLD_Geochem_Soils.csv → (220699, 104)\n",
      "[Saved] C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NWQLD\\NWQLD_Geochem_Soils_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# JUPYTER NOTEBOOK CELL — Clean numeric columns in NWQLD_Geochem_Rocks.csv\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Paths\n",
    "# =========================\n",
    "FOLDER = r\"C:\\Users\\Julian.Diaz\\OneDrive - XENITH CONSULTING PTY LTD\\Documents\\05_Geodatabases\\05_Excel\\NWQLD\"\n",
    "INPUT_FILE  = os.path.join(FOLDER, \"NWQLD_Geochem_Soils.csv\")\n",
    "OUTPUT_FILE = os.path.join(FOLDER, \"NWQLD_Geochem_Soils_cleaned.csv\")\n",
    "\n",
    "# Optional CSV read hints (set if needed)\n",
    "CSV_SEP = None        # e.g., \";\" if semicolon-delimited; None lets pandas guess\n",
    "CSV_UTF8_FIRST = True # try UTF-8 first, then latin1 fallback\n",
    "\n",
    "# Columns to convert to numbers + apply negative rules\n",
    "NUMERIC_COLUMNS = [\n",
    "    \"Au\",\"Au1\",\"Cu\",\"Pb\",\"Zn\",\"Ag\",\"As\",\"Bi\",\"Mo\",\"Mn\",\"Fe\",\"Ni\",\"Co\",\"Cr\",\"V\",\"Ba\",\"Cd\",\"Sn\",\n",
    "    \"Sb\",\"Hg\",\"Te\",\"P\",\"W\",\"Zr\",\"Ti\",\"Mg\",\"Th\",\"U\",\"Pt\",\"Pd\",\"S\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def normalize_number_string(s: str) -> str:\n",
    "    \"\"\"Normalize number-like text for robust parsing while preserving decimals.\"\"\"\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = s.strip()\n",
    "    s = s.replace(\"%\", \"\").replace(\"−\", \"-\")  # drop literal %; normalize minus\n",
    "    if \",\" in s and \".\" not in s:              # comma as decimal\n",
    "        s = s.replace(\",\", \".\")\n",
    "    s = re.sub(r\"[^0-9.\\-]+\", \"\", s)           # keep digits, ., -\n",
    "    if s.count(\".\") > 1:                       # collapse multiple dots\n",
    "        first = s.find(\".\")\n",
    "        s = s[:first+1] + s[first+1:].replace(\".\", \"\")\n",
    "    return s\n",
    "\n",
    "def to_numeric(series: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(series.map(normalize_number_string), errors=\"coerce\")\n",
    "\n",
    "def apply_negative_rules_to_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Apply your rules:\n",
    "      - values < -99  → NaN\n",
    "      - other negatives → abs(value) / 2 (becomes positive and halved)\n",
    "    \"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    s = s.mask(s < -99, np.nan)\n",
    "    s = s.mask((s < 0) & (s >= -99), abs(s) / 2)\n",
    "    return s\n",
    "\n",
    "# =========================\n",
    "# Load CSV with encoding fallback\n",
    "# =========================\n",
    "read_kwargs = {}\n",
    "if CSV_SEP is not None:\n",
    "    read_kwargs[\"sep\"] = CSV_SEP\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE, dtype=str, **read_kwargs) if CSV_UTF8_FIRST \\\n",
    "         else pd.read_csv(INPUT_FILE, dtype=str, encoding=\"latin1\", **read_kwargs)\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(INPUT_FILE, dtype=str, encoding=\"latin1\", **read_kwargs)\n",
    "\n",
    "print(f\"[Info] Loaded {os.path.basename(INPUT_FILE)} → {df.shape}\")\n",
    "\n",
    "# =========================\n",
    "# Clean numeric columns\n",
    "# =========================\n",
    "missing_cols = [c for c in NUMERIC_COLUMNS if c not in df.columns]\n",
    "for col in NUMERIC_COLUMNS:\n",
    "    if col in df.columns:\n",
    "        df[col] = to_numeric(df[col])\n",
    "        df[col] = apply_negative_rules_to_series(df[col])\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"[Warn] Missing columns (skipped): {missing_cols}\")\n",
    "\n",
    "# =========================\n",
    "# Save output\n",
    "# =========================\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"[Saved] {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d25fcb-adeb-429c-a2c8-182035528170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py311] *",
   "language": "python",
   "name": "conda-env-py311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
